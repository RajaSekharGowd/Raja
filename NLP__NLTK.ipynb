{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP _NLTK",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN+N83OJ//NtUQc8VUukTdA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RajaSekharGowd/Raja/blob/master/NLP__NLTK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8iDmGwkI4dx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a2854b9b-afcb-419e-c2e1-52ea4a286361"
      },
      "source": [
        "!pip install nltk"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN81zNF7Zi35",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "a94ce506-77dd-4fa1-b888-a06903258362"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "  \n",
        "  "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgoGuTspayCF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5QVaAIoazWY",
        "colab_type": "text"
      },
      "source": [
        "*** Tokenization :\n",
        "\n",
        "\n",
        "it is two types:\n",
        "1. word tokenzige  (from nltk import word_tokenize),          \n",
        "\n",
        "2. sentence tokenize (from nltk import sent_tokenize)***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LC7sa7tVakX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "552470cd-1a16-48fc-b9c3-c1ff6b62e312"
      },
      "source": [
        "import nltk\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "text=input(\"text here: \")\n",
        "print (word_tokenize(text))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text here:Hello, Raja! we are happy to see you here, thanks for coming.\n",
            "['Hello', ',', 'Raja', '!', 'we', 'are', 'happy', 'to', 'see', 'you', 'here', ',', 'thanks', 'for', 'coming', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40O0l1BBX1qK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ca2de3cc-0f2c-41f0-df57-d96fc203387a"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "sent=input(\"text place : \")\n",
        "print (sent_tokenize(sent))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text place : Hello, Raja! we are happy to see you here, thanks for coming.\n",
            "['Hello, Raja!', 'we are happy to see you here, thanks for coming.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dCjeKZHcpSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QS7hT5A1lPjI",
        "colab_type": "text"
      },
      "source": [
        "*** Parts Of Speech (POS) Baging and Chunking with NLTK  ***\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYQqXM1LX12_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "tokenizer = RegexpTokenizer(r'\\w+')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzfwlM3QS1P8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "70f027f6-7bc6-44fa-c8b3-b8e24c6f2e04"
      },
      "source": [
        "from nltk import pos_tag\n",
        "from nltk import RegexpParser\n",
        "text = \"Hello Raja we appriciate your interest towards Data Scince \".split()\n",
        "print(\"after split: \", text)\n",
        "tokens_tag = pos_tag(text)\n",
        "print(\"after tokens:\", tokens_tag)\n",
        "patterns=\"\"\"mychunk:{<NN.?>*<VBD.?>*<JJ.?>*<CC.?>}\"\"\"\n",
        "chunker= RegexpParser(patterns)\n",
        "print(\"after RegexpParser:\",chunker)\n",
        "output =chunker.parse(tokens_tag)\n",
        "print(\"after chunking:\", output)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "after split:  ['Hello', 'Raja', 'we', 'appriciate', 'your', 'interest', 'towards', 'Data', 'Scince']\n",
            "after tokens: [('Hello', 'NNP'), ('Raja', 'NNP'), ('we', 'PRP'), ('appriciate', 'VBP'), ('your', 'PRP$'), ('interest', 'NN'), ('towards', 'NNS'), ('Data', 'NNP'), ('Scince', 'NN')]\n",
            "after RegexpParser: chunk.RegexpParser with 1 stages:\n",
            "RegexpChunkParser with 1 rules:\n",
            "       <ChunkRule: '<NN.?>*<VBD.?>*<JJ.?>*<CC.?>'>\n",
            "after chunking: (S\n",
            "  Hello/NNP\n",
            "  Raja/NNP\n",
            "  we/PRP\n",
            "  appriciate/VBP\n",
            "  your/PRP$\n",
            "  interest/NN\n",
            "  towards/NNS\n",
            "  Data/NNP\n",
            "  Scince/NN)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd5wCSh8SxFf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FklCjxadtml3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "c14e75de-2d19-493d-9179-90474aa3108a"
      },
      "source": [
        "message = input(\"Tell me somrthing: \")\n",
        "tokens = nltk.word_tokenize(message)\n",
        "print(tokens)\n",
        "tag = nltk.pos_tag(tokens)\n",
        "print(tag)\n",
        "grammer = \"Np: {<DT>?<JJ>*<NN>}\"\n",
        "cp = nltk.RegexpParser(grammer)\n",
        "result = cp.parse(tag)\n",
        "print(result)\n",
        "\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tell me somrthing: Hello Raja we appriciate your interest towards Data Scince\n",
            "['Hello', 'Raja', 'we', 'appriciate', 'your', 'interest', 'towards', 'Data', 'Scince']\n",
            "[('Hello', 'NNP'), ('Raja', 'NNP'), ('we', 'PRP'), ('appriciate', 'VBP'), ('your', 'PRP$'), ('interest', 'NN'), ('towards', 'NNS'), ('Data', 'NNP'), ('Scince', 'NN')]\n",
            "(S\n",
            "  Hello/NNP\n",
            "  Raja/NNP\n",
            "  we/PRP\n",
            "  appriciate/VBP\n",
            "  your/PRP$\n",
            "  (Np interest/NN)\n",
            "  towards/NNS\n",
            "  Data/NNP\n",
            "  (Np Scince/NN))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48-9AVtmvg2Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hQnVYKb2RfF",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3hRJQ2d2SIF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "90aef539-7020-494e-fb99-324d40543b40"
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "e_words= [\"wait\", \"waiting\", \"waited\", \"waits\", \"cries\",\"crying\",\"cried\",\"cry\"]\n",
        "ps =PorterStemmer()\n",
        "for w in e_words:\n",
        "    rootWord=ps.stem(w)\n",
        "    print(rootWord)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "wait\n",
            "wait\n",
            "wait\n",
            "wait\n",
            "cri\n",
            "cri\n",
            "cri\n",
            "cri\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzn_YhcH2SQv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "a1943468-bb8f-4b77-a55d-a802f16aad89"
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "sentence=\"Hello Guru99, You have to builded a very good site and I love visiting your site.\"\n",
        "words = word_tokenize(sentence)\n",
        "ps = PorterStemmer()\n",
        "for w in words:\n",
        "\trootWord=ps.stem(w)\n",
        "\tprint(rootWord)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hello\n",
            "guru99\n",
            ",\n",
            "you\n",
            "have\n",
            "to\n",
            "build\n",
            "a\n",
            "veri\n",
            "good\n",
            "site\n",
            "and\n",
            "I\n",
            "love\n",
            "visit\n",
            "your\n",
            "site\n",
            ".\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Liy7QJg72SeF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I452NBvJ2SsO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}